# Lab 6 - Deploy de API Para AplicaÃ§Ã£o de IA com Ollama, Streamlit e Docker Compose

# Imports
import os
import streamlit as st
import requests

# ConfiguraÃ§Ã£o da pÃ¡gina do Streamlit
st.set_page_config(page_title = "Data Science Academy", page_icon = ":100:", layout = "centered")

# TÃ­tulo principal
st.title("ğŸ§ª Lab 6 - Deploy de API Para AplicaÃ§Ã£o de IA com Ollama, Streamlit e Docker Compose")

# Barra lateral com instruÃ§Ãµes
st.sidebar.header("ğŸš€ InstruÃ§Ãµes")
st.sidebar.markdown("""
1. **Digite** uma pergunta.
2. O chatbot irÃ¡ responder usando o modelo **Llama3** atravÃ©s da API do Ollama.
3. IA comete erros. SEMPRE verifique as respostas.

---

**ğŸ’¡ Exemplo de perguntas:**
- _"O que Ã© investimento no Tesouro Direto?"_
- _"Qual o sentido da vida?"_
- _"Quais sÃ£o as vantagens do modelo Llama3?"_
""")

# BotÃ£o de suporte na barra lateral
if st.sidebar.button("Suporte"):
    st.sidebar.write("No caso de dÃºvidas envie e-mail para: suporte@datascienceacademy.com.br")

# Inicializa mensagens na sessÃ£o
if "messages" not in st.session_state:
    st.session_state.messages = []

# Exibe mensagens anteriores
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input do usuÃ¡rio
if prompt := st.chat_input("Digite sua mensagem aqui..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Envia para API com spinner
    with st.spinner("A IA estÃ¡ processando sua solicitaÃ§Ã£o. Seja paciente e aguarde..."):
        response = requests.post(
            f"{os.getenv('API_URL')}/chat",
            json={"message": prompt}
        )

    # Recebe resposta do chatbot
    assistant_response = response.json()["response"]
    st.session_state.messages.append({"role": "assistant", "content": assistant_response})

    with st.chat_message("assistant"):
        st.markdown(assistant_response)





        